{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab7_Exercise2_DogvsCat_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloochocobar/CE888/blob/main/Labs/Lab7/Lab7_Exercise2_DogvsCat_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTh9DiKVslsJ"
      },
      "source": [
        "## Dogs vs. Cats \n",
        "\n",
        "In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/3000/1*bhFifratH9DjKqMBTeQG5A.gif)\n",
        "\n",
        "Ref: https://medium.com/@thegrigorian/rolling-in-the-deep-cnn-c8d3f7108c8c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSBI-_mSSY1g"
      },
      "source": [
        "Get your API Key from Kaggle using following steps:\n",
        "1. Login to [Kaggle](https://www.kaggle.com/) or Register if you don't have account\n",
        "2. Open Dataset (https://www.kaggle.com/c/dogs-vs-cats/rules) and accept terms and condition. \n",
        "3. On the top right corner click on your Icon and go to accounts and press a button \"Create New API Token\". It will download a JSON file containing your username and key. \n",
        "4. Now, paste both below. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmXSOc0tZIGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56666b7e-721f-46c5-dac0-e16db6bfb44a"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"deveshfuse\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"d5bdc41883a3e030d4dab175bd082970\" # key from the json file\n",
        "!kaggle competitions download -c dogs-vs-cats # api copied from kaggle (https://www.kaggle.com/c/dogs-vs-cats/data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train.zip to /content\n",
            " 97% 527M/543M [00:03<00:00, 163MB/s]\n",
            "100% 543M/543M [00:03<00:00, 148MB/s]\n",
            "Downloading test1.zip to /content\n",
            " 97% 263M/271M [00:02<00:00, 123MB/s]\n",
            "100% 271M/271M [00:02<00:00, 122MB/s]\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 85.5MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiwIL8d1n7eS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22477cc8-e06f-46cd-e329-3e19828890b9"
      },
      "source": [
        "# Unzip training data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/train.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa2Bj5i7pPKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf916db9-926a-4d1b-9601-ec40b14e661c"
      },
      "source": [
        "# Get all the paths\n",
        "data_dir_list = os.listdir('/content/train')\n",
        "#print(data_dir_list)\n",
        "path, dirs, files = next(os.walk(\"/content/train\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ERlHkfHqpK8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "934e9b7a-d6b9-4042-cd70-fc3a2f0153c7"
      },
      "source": [
        "# Make new base directory\n",
        "original_dataset_dir = '/content/train'\n",
        "base_dir = '/content/cats_and_dogs_small'\n",
        "os.mkdir(base_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-b62abd036009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moriginal_dataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/cats_and_dogs_small'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/cats_and_dogs_small'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AANB1UJ6rQhM"
      },
      "source": [
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULRgL9s9rV8T"
      },
      "source": [
        "import shutil\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul3XAbIyr7vC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d0f1ba-7308-4d1e-9af7-79e97afc8244"
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9yTA21_r-ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3974f3-0eb2-4c9c-f2c9-3ba700a34bcc"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mG8wekxsBVS"
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zS4Klm8qWp6"
      },
      "source": [
        "## Using ImageDataGenerator to read images from directories\n",
        "As you know by now, data should be formatted into appropriately preprocessed floatingpoint tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n",
        "\n",
        "* Read the picture files.\n",
        "* Decode the JPEG content to RGB grids of pixels.\n",
        "* Convert these into floating-point tensors.\n",
        "* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
        "\n",
        "It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class ImageDataGenerator,which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ7XU7t9sEh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a53d841-729d-4f6d-9587-79e61ae3c79e"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEgLywySqm4u"
      },
      "source": [
        "Let’s fit the model to the data using the generator. You do so using the fit_generator method, the equivalent of fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely,like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring anepoch over. This is the role of the `steps_per_epoch` argument: after having drawn `steps_per_epoch` batches from the generator—that is, after having run for `steps_per_epoch` gradient descent steps—the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples.\n",
        "\n",
        "When using fit_generator, you can pass a validation_data argument, much as with the fit method. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMyfPphJsJG6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aca5131-3c5e-4eab-f8e8-f17497ef10d8"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=30,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 37s 62ms/step - loss: 0.6909 - acc: 0.5338 - val_loss: 0.6705 - val_acc: 0.5700\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.6612 - acc: 0.6069 - val_loss: 0.6493 - val_acc: 0.6300\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.6177 - acc: 0.6502 - val_loss: 0.6264 - val_acc: 0.6600\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.5743 - acc: 0.6965 - val_loss: 0.5243 - val_acc: 0.7200\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.5225 - acc: 0.7473 - val_loss: 0.6379 - val_acc: 0.6350\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.5070 - acc: 0.7498 - val_loss: 0.5852 - val_acc: 0.6550\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.4811 - acc: 0.7764 - val_loss: 0.5452 - val_acc: 0.7100\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.4564 - acc: 0.7866 - val_loss: 0.5108 - val_acc: 0.7700\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.4293 - acc: 0.7941 - val_loss: 0.6015 - val_acc: 0.6900\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.4064 - acc: 0.8184 - val_loss: 0.4877 - val_acc: 0.7550\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.3669 - acc: 0.8527 - val_loss: 0.4928 - val_acc: 0.7800\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.3673 - acc: 0.8456 - val_loss: 0.5402 - val_acc: 0.7250\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.3313 - acc: 0.8535 - val_loss: 0.5656 - val_acc: 0.7450\n",
            "Epoch 14/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.3093 - acc: 0.8696 - val_loss: 0.5444 - val_acc: 0.7550\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.2956 - acc: 0.8848 - val_loss: 0.5891 - val_acc: 0.7400\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 6s 60ms/step - loss: 0.2754 - acc: 0.8924 - val_loss: 0.5780 - val_acc: 0.7250\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 6s 60ms/step - loss: 0.2593 - acc: 0.8960 - val_loss: 0.5276 - val_acc: 0.7800\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.2153 - acc: 0.9265 - val_loss: 0.5531 - val_acc: 0.7800\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.2288 - acc: 0.9073 - val_loss: 0.5808 - val_acc: 0.7800\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.1974 - acc: 0.9306 - val_loss: 0.6257 - val_acc: 0.7200\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.1987 - acc: 0.9345 - val_loss: 0.4878 - val_acc: 0.8050\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.1721 - acc: 0.9370 - val_loss: 0.5924 - val_acc: 0.7850\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.1408 - acc: 0.9537 - val_loss: 0.8093 - val_acc: 0.7200\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.1239 - acc: 0.9619 - val_loss: 0.6980 - val_acc: 0.7650\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.1086 - acc: 0.9677 - val_loss: 0.6391 - val_acc: 0.7450\n",
            "Epoch 26/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.0955 - acc: 0.9747 - val_loss: 0.7615 - val_acc: 0.7850\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.0803 - acc: 0.9803 - val_loss: 0.6593 - val_acc: 0.8000\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.0939 - acc: 0.9714 - val_loss: 0.8246 - val_acc: 0.7450\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 6s 58ms/step - loss: 0.0649 - acc: 0.9833 - val_loss: 0.9235 - val_acc: 0.7550\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 6s 59ms/step - loss: 0.0599 - acc: 0.9831 - val_loss: 1.0371 - val_acc: 0.7350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZaZ2HWZsNUi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "0f95ab72-30d3-456d-9aff-2a2c5345b517"
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKZmXmBcq_8-"
      },
      "source": [
        "## Convolutional Networks with Dropout\n",
        "\n",
        "![alt text](https://camo.githubusercontent.com/ee6fa1073247cd2c3d241300caf110d7a7541bc5/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4972644a355067684439596f4f7956415137334d4a772e676966)\n",
        "\n",
        "Ref: https://github.com/mneha4/Training-Neural-Nets---Guidelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu3cqeYQrDeN"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSeLpvY0rH7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8684d58a-aa55-4776-b56b-8fa71e6dff19"
      },
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCacb41ePD4-",
        "outputId": "490d9240-705a-4d45-d4d5-63e1896bef3a"
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=20,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.6776 - acc: 0.5725 - val_loss: 0.6682 - val_acc: 0.5930\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.6617 - acc: 0.5940 - val_loss: 0.6591 - val_acc: 0.6070\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 0.6494 - acc: 0.6165 - val_loss: 0.6265 - val_acc: 0.6310\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.6414 - acc: 0.6285 - val_loss: 0.7065 - val_acc: 0.5430\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.6286 - acc: 0.6380 - val_loss: 0.6096 - val_acc: 0.6560\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.6199 - acc: 0.6525 - val_loss: 0.5913 - val_acc: 0.6740\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.6149 - acc: 0.6590 - val_loss: 0.5888 - val_acc: 0.6880\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.6013 - acc: 0.6745 - val_loss: 0.5768 - val_acc: 0.6900\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.6023 - acc: 0.6615 - val_loss: 0.5823 - val_acc: 0.6910\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.5916 - acc: 0.6800 - val_loss: 0.5644 - val_acc: 0.7020\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5725 - acc: 0.6950 - val_loss: 0.6223 - val_acc: 0.6740\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.5723 - acc: 0.6945 - val_loss: 0.5408 - val_acc: 0.7200\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5683 - acc: 0.7030 - val_loss: 0.5350 - val_acc: 0.7190\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 0.5667 - acc: 0.7070 - val_loss: 0.5519 - val_acc: 0.7040\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5589 - acc: 0.7075 - val_loss: 0.5274 - val_acc: 0.7330\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5536 - acc: 0.7135 - val_loss: 0.5342 - val_acc: 0.7310\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 16s 163ms/step - loss: 0.5603 - acc: 0.7060 - val_loss: 0.5447 - val_acc: 0.7250\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5402 - acc: 0.7255 - val_loss: 0.5256 - val_acc: 0.7470\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 0.5354 - acc: 0.7310 - val_loss: 0.4982 - val_acc: 0.7600\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 0.5536 - acc: 0.7205 - val_loss: 0.5388 - val_acc: 0.7190\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRdU5yrkUF_b"
      },
      "source": [
        "# Task 2:\n",
        "\n",
        "We have used Dropout to enhance the performance of the CNN model. Can you please use whatever you like to further enhance the performance from `val_acc: 0.7506`? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYyHK8cMOk6Z",
        "outputId": "d4329c6d-6886-4bb2-9cc3-648ac0734df1"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=1500//32,\n",
        "                              epochs=32,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=1500//32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "46/46 [==============================] - ETA: 0s - loss: 0.5421 - acc: 0.7276WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 46 batches). You may need to use the repeat() function when building your dataset.\n",
            "46/46 [==============================] - 12s 272ms/step - loss: 0.5421 - acc: 0.7276 - val_loss: 0.4956 - val_acc: 0.7590\n",
            "Epoch 2/32\n",
            "46/46 [==============================] - 10s 211ms/step - loss: 0.5127 - acc: 0.7527\n",
            "Epoch 3/32\n",
            "46/46 [==============================] - 10s 211ms/step - loss: 0.5357 - acc: 0.7163\n",
            "Epoch 4/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.5280 - acc: 0.7383\n",
            "Epoch 5/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.5474 - acc: 0.7266\n",
            "Epoch 6/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.5499 - acc: 0.7054\n",
            "Epoch 7/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.5164 - acc: 0.7479\n",
            "Epoch 8/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.5116 - acc: 0.7514\n",
            "Epoch 9/32\n",
            "46/46 [==============================] - 10s 210ms/step - loss: 0.5237 - acc: 0.7376\n",
            "Epoch 10/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.5110 - acc: 0.7479\n",
            "Epoch 11/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.5060 - acc: 0.7569\n",
            "Epoch 12/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.5144 - acc: 0.7371\n",
            "Epoch 13/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.5107 - acc: 0.7418\n",
            "Epoch 14/32\n",
            "46/46 [==============================] - 10s 211ms/step - loss: 0.5025 - acc: 0.7603\n",
            "Epoch 15/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.4918 - acc: 0.7514\n",
            "Epoch 16/32\n",
            "46/46 [==============================] - 10s 215ms/step - loss: 0.4939 - acc: 0.7649\n",
            "Epoch 17/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.4932 - acc: 0.7589\n",
            "Epoch 18/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.4789 - acc: 0.7697\n",
            "Epoch 19/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.4950 - acc: 0.7431\n",
            "Epoch 20/32\n",
            "46/46 [==============================] - 10s 211ms/step - loss: 0.4923 - acc: 0.7617\n",
            "Epoch 21/32\n",
            "46/46 [==============================] - 10s 210ms/step - loss: 0.4870 - acc: 0.7658\n",
            "Epoch 22/32\n",
            "46/46 [==============================] - 10s 210ms/step - loss: 0.4886 - acc: 0.7734\n",
            "Epoch 23/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.4797 - acc: 0.7630\n",
            "Epoch 24/32\n",
            "46/46 [==============================] - 10s 214ms/step - loss: 0.4964 - acc: 0.7493\n",
            "Epoch 25/32\n",
            "46/46 [==============================] - 10s 210ms/step - loss: 0.4723 - acc: 0.7699\n",
            "Epoch 26/32\n",
            "46/46 [==============================] - 10s 210ms/step - loss: 0.5012 - acc: 0.7527\n",
            "Epoch 27/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.4756 - acc: 0.7651\n",
            "Epoch 28/32\n",
            "46/46 [==============================] - 10s 212ms/step - loss: 0.4718 - acc: 0.7663\n",
            "Epoch 29/32\n",
            "46/46 [==============================] - 10s 211ms/step - loss: 0.4772 - acc: 0.7740\n",
            "Epoch 30/32\n",
            "46/46 [==============================] - 10s 214ms/step - loss: 0.4798 - acc: 0.7724\n",
            "Epoch 31/32\n",
            "46/46 [==============================] - 10s 213ms/step - loss: 0.4938 - acc: 0.7582\n",
            "Epoch 32/32\n",
            "46/46 [==============================] - 10s 217ms/step - loss: 0.4761 - acc: 0.7636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8b27c7aa50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usTIdNiLScnJ"
      },
      "source": [
        "Hee we can see at epoch 32 val_accuracy, acc=0.7636 which is greater than 7506"
      ]
    }
  ]
}