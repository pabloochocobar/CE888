{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise_1_VAE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pabloochocobar/CE888/blob/main/Labs/Lab9/Exercise_1_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZWcfrv2f-FL"
      },
      "source": [
        "Make sure your GPU is connceted to RunTime. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBRdIlLAf2V1"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "# from keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v1.keras.backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuMRhNWjgMfz"
      },
      "source": [
        "# Build the encoder\n",
        "img_shape = (28, 28, 1)\n",
        "batch_size = 16\n",
        "latent_dim = 2 # Dimensionality of the latent space: a 2D plane\n",
        "input_img = keras.Input(shape=img_shape)\n",
        "x = layers.Conv2D(32, 3, padding='same', activation='relu')(input_img)\n",
        "x = layers.Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(x)\n",
        "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "shape_before_flattening = K.int_shape(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# The input image ends up being encoded into these two parameters\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x)\n",
        "print(z_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAfiNJPfgcvh"
      },
      "source": [
        "Next is the code for using `z_mean` and `z_log_var`, the parameters of the statistical distribution assumed to have produced `input_img`, to generate a latent space point `z`. Here, you wrap some arbitrary code (built on top of Keras backend primitives) into a `Lambda` layer. In Keras, everything needs to be a layer, so code that isn’t part of a builtin layer should be wrapped in a `Lambda` (or in a custom layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJKLu_vPgqnE"
      },
      "source": [
        "# Latent-space-sampling function\n",
        "def sampling(args):\n",
        "    z_mean, z_log_var = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mean + K.exp(z_log_var) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4CudPsFgwUz"
      },
      "source": [
        "### VAE decoder network, mapping latent space points to images\n",
        "\n",
        "The following listing shows the decoder implementation. You reshape the vector `z `to the dimensions of an image and then use a few convolution layers to obtain a final image output that has the same dimensions as the original `input_img`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLKF53okg8x0"
      },
      "source": [
        "decoder_input = layers.Input(K.int_shape(z)[1:]) # Input where you’ll feed z\n",
        "\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]), \n",
        "                 activation='relu')(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
        "x = layers.Conv2DTranspose(32, 3,padding='same',\n",
        "                           activation='relu',strides=(2, 2))(x)\n",
        "x = layers.Conv2D(1, 3,padding='same',activation='sigmoid')(x)\n",
        "decoder = Model(decoder_input, x)\n",
        "z_decoded = decoder(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz8XqelihBWX"
      },
      "source": [
        "#### Custom layer used to compute the VAE loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5GO8PvehB3p"
      },
      "source": [
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "    \n",
        "    def vae_loss(self, x, z_decoded):\n",
        "        x = K.flatten(x)\n",
        "        z_decoded = K.flatten(z_decoded)\n",
        "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "        kl_loss = -5e-4 * K.mean(\n",
        "            1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "    \n",
        "    #You implement custom layers You don't use by writing a call method.\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        z_decoded = inputs[1]\n",
        "        loss = self.vae_loss(x, z_decoded)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        return x # You don't use this output, but the layer must return something.\n",
        "    \n",
        "y = CustomVariationalLayer()([input_img, z_decoded])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1nRvL2RhIhI"
      },
      "source": [
        "#### Training the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQlLhVqZhL9s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4119a320-b6cd-4240-9154-8fb819d5427d"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# import tensorflow.compat.v1.keras.backend as K\n",
        "# import tensorflow as tf\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "vae = Model(input_img, y)\n",
        "vae.compile(optimizer='rmsprop', loss=None)\n",
        "vae.summary()\n",
        "\n",
        "(x_train, _), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "vae.fit(x=x_train, y=None, shuffle=True, epochs=10, batch_size=batch_size, validation_data=(x_test, None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Output custom_variational_layer missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 28, 28, 32)   320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 14, 14, 64)   18496       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 12544)        0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 32)           401440      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            66          dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            66          dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 2)            0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model (Functional)              (None, 28, 28, 1)    56385       lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer (Custo (None, 28, 28, 1)    0           input_1[0][0]                    \n",
            "                                                                 model[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 550,629\n",
            "Trainable params: 550,629\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "59888/60000 [============================>.] - ETA: 0s - loss: 603.6034"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 59s 989us/sample - loss: 602.4770 - val_loss: 0.1975\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 21s 353us/sample - loss: 0.1941 - val_loss: 0.1929\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 22s 362us/sample - loss: 0.1893 - val_loss: 0.1889\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 21s 355us/sample - loss: 0.1868 - val_loss: 0.1853\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 21s 352us/sample - loss: 0.1853 - val_loss: 0.1849\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 21s 348us/sample - loss: 0.1841 - val_loss: 0.1829\n",
            "Epoch 7/10\n",
            "12816/60000 [=====>........................] - ETA: 15s - loss: 0.1838"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miWjlBa5jerm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "n = 15\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
        "        x_decoded = decoder.predict(z_sample, batch_size=batch_size)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "            j * digit_size: (j + 1) * digit_size] = digit\n",
        "        \n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}